model   MeshGraphNets
mode    Train  # Train / Inference
gpu_ids 0      # -1 for CPU, GPU ids for multi-GPU training
log_file_dir    train0.log
%   Common params
%   Dim1		1000 # number of parameters
%   Dim2		1   # number of timesteps
%   Dim3		95008 # num nodes, unused in GNN
input_var   4   # number of input variables: x_disp, y_disp, z_disp, stress (excluding node types)
output_var  4   # number of output variables: x_disp, y_disp, z_disp, stress (excluding node types)
edge_var    4   # dx, dy, dz, disp
'
%   Network parameters
dataset_dir ./dataset/deforming_plate.h5
norm_min    -0.7  # Normalization range minimum
norm_max    0.7   # Normalization range maximum
message_passing_num 15
Training_epochs	50
Batch_size	10
LearningR	0.001
Latent_dim	128	# MeshGraphNets latent dimension
num_workers 10
std_noise   0.0000000000000000000001
verbose     False
'
% Memory Optimization
use_checkpointing   False
'
% Node Type Parameters
use_node_types  True    # Add one-hot encoded node types to node features
'
% World Edge Parameters
use_world_edges         True
world_radius_multiplier 1.5     # r_world = multiplier * min_mesh_edge_length (auto-computed)
world_max_num_neighbors 64      # Max neighbors per node in world edge radius query (prevents edge explosion)
world_edge_backend      scipy_kdtree   # Backend: torch_cluster (GPU, fast) or scipy_kdtree (CPU, fallback)
% Test set control
display_testset True
test_batch_idx  0, 1, 2, 3
plot_feature_idx    -2  # Feature index to visualize in plots (-1 = last feature, i.e., stress)